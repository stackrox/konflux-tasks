apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: post-bigquery-metrics
spec:
  description: Adds a record to ACS BigQuery table about the pipeline's execution status.
  params:
  - name: AGGREGATE_TASKS_STATUS
    default: ''
    description: |
      Status of normal (non-final) tasks of the pipeline.
      https://tekton.dev/docs/pipelines/pipelines/#using-aggregate-execution-status-of-all-tasks
      When the task is placed in the pipeline's finally block, pass here `$(tasks.status)`.
      When this task is in the beginning of the pipeline, don't pass anything.
  results:
  volumes:
  - name: gcp-service-account
    secret:
      optional: false
      secretName: konflux-metrics-gcp-service-account
  steps:
  - name: update-bigquery
    image: gcr.io/google.com/cloudsdktool/google-cloud-cli:stable@sha256:767516bf8e50f22c074c07e1138844744b80345e5ca315ea413a88ab22e36089
    volumeMounts:
    - name: gcp-service-account
      mountPath: /mnt/gcp-service-account
    env:
    - name: PIPELINE_RUN_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.labels['tekton.dev/pipelineRun']
    - name: ORIGINAL_PIPELINE_RUN_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.labels['pipelinesascode.tekton.dev/original-prname']
    - name: REPO_URL
      valueFrom:
        fieldRef:
          fieldPath: metadata.annotations['pipelinesascode.tekton.dev/repo-url']
    - name: SOURCE_BRANCH
      valueFrom:
        fieldRef:
          fieldPath: metadata.annotations['pipelinesascode.tekton.dev/source-branch']
    - name: PULL_REQUEST_NUMBER
      valueFrom:
        fieldRef:
          fieldPath: metadata.labels['pipelinesascode.tekton.dev/pull-request']
    - name: COMMIT_SHA
      valueFrom:
        fieldRef:
          fieldPath: metadata.labels['pipelinesascode.tekton.dev/sha']
    script: |
      #!/usr/bin/env bash

      set -euo pipefail

      GCP_PROJECT="acs-san-stackroxci"
      TABLE_NAME="${GCP_PROJECT}.ci_metrics.stackrox_jobs"

      gcloud auth activate-service-account --key-file /mnt/gcp-service-account/konflux-metrics-gcp-service-account
      gcloud config set project "${GCP_PROJECT}"

      AGGREGATE_TASKS_STATUS="$(params.AGGREGATE_TASKS_STATUS)"

      bq query \
        --use_legacy_sql=false \
        --parameter="id::${PIPELINE_RUN_NAME}" \
        --parameter="name::${ORIGINAL_PIPELINE_RUN_NAME}" \
        --parameter="repo::${REPO_URL}" \
        --parameter="branch::${SOURCE_BRANCH}" \
        --parameter="pr_number:INTEGER:${PULL_REQUEST_NUMBER:-NULL}" \
        --parameter="commit_sha::${COMMIT_SHA}" \
        --parameter="outcome::${AGGREGATE_TASKS_STATUS:-NULL}" \
        "
        -- Create a temporary table for holding a record for this job with the same schema as the target table.
        CREATE TEMP TABLE _SESSION.this_job AS SELECT * FROM ${TABLE_NAME} LIMIT 0;

        -- Add the job's record into the temporary table.
        INSERT INTO _SESSION.this_job
          (id, name, repo, branch, pr_number, commit_sha, started_at, stopped_at, outcome, ci_system)
          VALUES
          (@id, @name, @repo, @branch, @pr_number, @commit_sha, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP(), @outcome, 'konflux');

        -- Upsert a record from the temporary table into the target table.
        MERGE INTO ${TABLE_NAME} T
        USING _SESSION.this_job S
        ON T.id = S.id
        WHEN NOT MATCHED BY TARGET THEN
          INSERT ROW
        WHEN MATCHED THEN
          UPDATE SET stopped_at = S.stopped_at, outcome = S.outcome;

        -- Remove the temporary table (sooner than Google would do it).
        DROP TABLE _SESSION.this_job;
        "
